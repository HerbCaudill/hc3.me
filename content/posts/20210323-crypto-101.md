---
title: Cryptography 101
subtitle: Everything you need to know about digital encryption and signatures but were embarrassed to ask.

description: |
  Cryptography is a fundamental piece of the digital infrastructure we all rely on, and yet most of
  us are pretty fuzzy on how it actually works. I've written this for programmers, as well as
  curious civilians, who would like a clearer idea of what the pieces are and how they fit together.

date: '2021-03-23'
thumbnail: /images/posts/crypto/crypto.thumbnail.jpg
image: /images/posts/crypto/crypto.jpg
caption: 'In this letter to James Monroe, dated February 16, 1804, James Madison encrypted the sensitive parts. <i><a href="https://www.loc.gov/resource/mjm.08_0143_0147/?sp=4">Library of Congress</a></i>'
tags: software
---

Modern digital cryptography can be intimidating, even for seasoned programmers and other smart
people. When I first started work on
[@localfirst/auth](/words/20210228-establishing-trust-in-a-world-without-servers), I felt so
self-conscious about my own ignorance of some really basic stuff that I hesitated to ask my peers
for pointers.

And there was a gap in the educational materials available online between hand-wavy things that only
explained by way of analogy, and in-the-weeds things that only explained by way of inscrutable
mathematical proofs. I wanted to have a clear grasp of the math at work.

And I've found that that is possible: The basic concepts underlying crypto are actually well within
reach using nothing but high-school math.

The purpose of this article is to explain crypto while still respecting your intelligence. I'll
focus on these five operations:

1. Symmetric encryption
1. Random number generation
1. Hashes
1. Signatures
1. Asymmetric encryption

For each of these

## Prologue: Numbers all the way down

<figure class='figure-xs'>

![](/images/posts/crypto/ascii.png)

The [ASCII](https://en.wikipedia.org/wiki/ASCII) standard defined numerical equivalents for 95
printable characters: upper-case **A** is 65, lower-case **z** is 122. The
[Unicode](https://en.wikipedia.org/wiki/Unicode) standard has expanded on that to encode 143,859
characters in 154 scripts, from Cyrillic to Hiragana to Emoji.

</figure>

The most fundamental intuition required to understand digital cryptography is that everything is
numbers. That's what "digital" means. Whether it's an instant message or a scan of your bank
statement, it's a series of numbers.

What that means is that we can think of all of the operations listed above as functions that
take a number and return a different number.

In this article I'll focus on messages consisting of **text**, like `The eagle lands at midnight`.
Over time, we've come up with lots of different ways to express letters and characters as numbers.
The only encodings that matter for our purposes is Unicode (which is a superset of ASCII).

In both ASCII and Unicode, the message `The eagle lands at midnight` is encoded as follows:

```txt
T  h   e      e   a  g   l   e      l   a  n   d   s      a  t      m   i   d   n   i   g   h   t
84 104 101 32 101 97 103 108 101 32 108 97 110 100 115 32 97 116 32 109 105 100 110 105 103 104 116
```

## Symmetric encryption

**Symmetric** (secret-key) encryption is so called because both the sender and the receiver have the
same secret key. (In **asymmetric** encryption, also known as **public-key** encryption, the sender
and receiver have different keys. We'll look at that later.)

Suppose Alice and Bob both know the secret passphrase `Horse Battery Correct Staple`, and Alice is
going to send our message, `The eagle lands at midnight`, to Bob.

Alice converts the message to binary. `84` in binary is `01010100`, `104` is `01101000`, and so on.

```txt
T        h        e        space    e        a        ...
84       104      101      32       101      97
01010100 01101000 01100101 00100000 01100101 01100001
```

She also converts the passphrase to binary.

```txt
H        o        r        s        e        space    ...
72       111      114      115      101      32
01001000 01101111 01110010 01110011 01100101 00100000
```

<aside>

XOR (also notated ⊕) is an operation on two binary digits that returns **1** if the two digits are **different**, and
**0** if they are the **same**:

0 ⊕ 0 = 0  
0 ⊕ 1 = 1  
1 ⊕ 0 = 1  
1 ⊕ 1 = 0

</aside>

To encrypt the message using the passphrase, she takes each bit of the message and the corresponding
bit of the passphrase, and performs an `XOR` operation to come up with a new binary number:

```txt
    01010100 01101000 01100101 00100000 01100101 01100001 ... (message)
XOR 01001000 01101111 01110010 01110011 01100101 00100000 ... (passphrase)
---------------------------------------------------------
    00011100 00000111 00010111 01010011 00000000 01000001 ... (cipher)
```

She gets the following **cipher**, which she can send to Bob:

```txt
00011100 00000111 00010111 01010011 00000000 01000001 ...
```

The `XOR` operation has the useful property that you can run it "backwards" to retrieve one of the
original inputs: if `A ⊕ B = C`, then `C ⊕ B = A`. So when Bob receives the cipher, he can XOR
it with the passphrase to recover the original message:

```txt
    00011100 00000111 00010111 01010011 00000000 01000001 ... (cipher)
XOR 01001000 01101111 01110010 01110011 01100101 00100000 ... (passphrase)
---------------------------------------------------------
    01010100 01101000 01100101 00100000 01100101 01100001 ... (message)
```

If the key is as long or longer than the message and you never re-use it, it's equivalent to a spy's
**one-time pad**, which is the gold standard for encryption: It offers **perfect secrecy** because
it is mathematically impossible to crack.

What happens if the message is longer than the key, though?

We _could_ repeat the key as many times as necessary to have a mask that's as long as the text to be
encrypted. Suppose the key is `passw0rd`.

```txt
The eagle lands at midnight
passw0rdpassw0rdpassw0rdpas
```

To show why this might be a problem, let's take it to an extreme: Suppose our key is just the letter
**X** (`01011000` in binary).

```txt
    01010100 01101000 01100101 00100000 01100101 01100001 ... (message)
XOR 01011000 01011000 01011000 01011000 01011000 01011000 ... (repeated key)
    ------------------------------------------------------------
    00001100 00110000 00111101 01111000 00111101 00111001 ... (cipher)
```

<figure class='figure-md' >

![](/images/posts/crypto/cryptogram.jpg)

If your grandpa can crack it over coffee, it's probably not secure.

</figure>

If you've ever solved a "cryptogram" in a newspaper or a puzzle book, you might see the problem with
this approach. A cryptogram is an example of a **substitution cipher**: each letter in the alphabet
is substituted with another. For example, this cipher substitutes **A** for **E**, **Q** for **T**,
and so on:

```txt
THE EAGLE LANDS AT MIDNIGHT
QDA AZCIA IZKRP ZQ JFRKFCDQ
```

Substitution ciphers can be solved so easily that they put them in the newspaper next to crossword
puzzles, so that people can work them out with pencil and paper for fun.

<figure class='figure-xs'>

![](/images/posts/crypto/distribution.png)

In English, **E** is the most common letter, followed by **T**, then **A**, **I**, **N**, **O**, and **S**.

</figure>

How? For one thing, you can use statistics about letter frequency to your advantage: A letter that
appears 12% of the time is likely to be `E`, and so on. The longer the message is (or the more
messages you have to work with) the bigger our statistical sample and the more helpful this
technique is.

Our example of XOR encryption with a repeated single-letter key is just a substitution cipher: Every
**T** (`01010100`) is replaced with `00001100`; every **E** (`01100101`) is replaced with
`00111101`; and so on.

With a longer repeated key like `passw0rd` this wouldn't be quite as easy, but given a long-enough
message, it's still possible. The same logic applies to re-using the same key for multiple messages:
The more examples you have of messages encrypted using the same key, the better your chances of
cracking the code.

In order for our symmetric encryption algorithm to be secure, what we need is a way to "stretch" our
key to the size of the message, **without** repeating it. To do that, first we need to explore the
related concepts of **randomness** and **hashes**.

## Randomness

A source of unpredictability is a fundamental requirement for any form of information security. If
you can make educated guesses about the next key that a system will generate, then the system's
secrets are no longer secret.

People can be a source of randomness. In the examples above, we have Alice and Bob using a secret
passphrase --- `Horse Battery Correct Staple` --- to encrypt and decrypt. That might seem totally
random to you --- unless you've seen this XKCD cartoon.

<figure class='figure-md'>

![Password Strength](https://imgs.xkcd.com/comics/password_strength.png)

Since this passphrase appeared in this cartoon, it's no longer a good choice --- but that hasn't
stopped people from using it!

</figure>

The passwords we humans come up with are often not as random as we think they are. This is partly
because we shrink the total possibility space in various ways that make our passwords easier to
remember; thus `passw0rd` and `abc123`. But even if you take memorability out of the picture
--- say, by asking someone to type a series of random numbers --- the results are more predictable
than we might think.

<figure class='figure-xs'>

![](https://miro.medium.com/max/640/1*pMNDxIQh72rFs7lsW6Ww0w.png)

TODO [credit](https://medium.com/@markshovman/human-generated-randomness-ac0e3d2f394f)

</figure>

At any rate, encryption keys are typically not generated by us humans, but by our devices --- our
laptops, our servers, our smartphones. So how well do computers do at generating randomness?

This is a harder problem than it seems. You wouldn't think that unpredictability would be in short
supply. Unpredictability is maybe the most salient feature of physical reality.

> "It is difficult to make predictions, especially about the future." _--- (probably not) Yogi Berra_

In the natural world, entropy is the rule, not the exception. Any victories that we achieve against
it are fleeting in the inexorable march towards the heat death of the universe. ([Enjoy
Arby's!](https://twitter.com/nihilist_arbys))

That's why we invented computers; they're a weapon for humanity in this battle against chaos.
They're state machines. Their whole point is to be orderly and predictable. Same input, same output,
every single time.

But what that means is that computers can't really **do** unpredictability. That's the bad news. The
good news is that we are surrounded by entropy, and the trick is to bring that outside randomness
into the computer.

<figure>

![Cloudflare Lava Lamp Wall](https://blog.cloudflare.com/content/images/2017/11/lava-lamps.jpg)

As a source of entropy, Cloudflare's wall of lava lamps is mostly for show. But it does illustrate
the idea that true randomness has to come from the physical world into the computer.

</figure>

Cloudflare famously has a wall of lava lamps in their San Francisco lobby. The movement of the blobs
of wax in the hot oil in a lava lamp is known to be chaotic. A video feed from a camera monitoring
the lava lamps --- plus an additional bit of randomness from the movement of people in the lobby ---
populates an "entropy pool" from which random numbers can be drawn. And it [doesn't stop
there](https://www.cloudflare.com/learning/ssl/lava-lamp-encryption/):

> "The other two main Cloudflare offices are in London and Singapore, and each office has its own
> method for generating random data from real-world inputs. London takes photos of a double-pendulum
> system mounted in the office (a pendulum connected to a pendulum, the movements of which are
> mathematically unpredictable). The Singapore office measures the radioactive decay of a pellet of
> uranium."

The lava lamps and the uranium pellet are more nerdy PR stunts than anything. Any modern device has
several sources of randomness:

- Actual physical sensors like accelerometers and CPU temperature monitors
- Minute variations in input from the user, such as mouse movements and the millisecond-level timing
  of keystrokes
- Details of system's overall state, such as hard drive utilization, IDs of running processes, the
  system clock, or CPU counters

All of these can be combined to create something that's unpredictable enough that we don't need to
keep our webcams pointed at a lava lamp. Modern devices use techniques like these to provide us with
truly random numbers.

<figure class='figure-xs'>

![JohnvonNeumann-LosAlamos.gif](https://upload.wikimedia.org/wikipedia/commons/5/5e/JohnvonNeumann-LosAlamos.gif)

"Anyone who considers arithmetical methods of producing random digits is, of course, in a state of
sin.” _--- John von Neumann_

</figure>

### True randomness vs. pseudo-randomness

## Hashes

## Digital signatures

## Asymmetric (public-key) encryption

```

```

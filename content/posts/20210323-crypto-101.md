---
title: Cryptography 101
subtitle: Everything you need to know about digital encryption and signatures but were embarrassed to ask.

description: |
  Cryptography is a fundamental piece of the digital infrastructure we all rely on, and yet most of
  us are pretty fuzzy on how it actually works. I've written this for programmers, as well as
  curious civilians, who would like a clearer idea of what the pieces are and how they fit together.

date: '2021-03-23'
thumbnail: /images/posts/crypto/crypto.thumbnail.jpg
image: /images/posts/crypto/crypto.jpg
caption: 'In this letter to James Monroe, dated February 16, 1804, James Madison encrypted the sensitive parts. <i><a href="https://www.loc.gov/resource/mjm.08_0143_0147/?sp=4">Library of Congress</a></i>'
tags: software
---

Modern digital cryptography can be intimidating, even for seasoned programmers and other smart
people. When I first started work on
[@localfirst/auth](/words/20210228-establishing-trust-in-a-world-without-servers), I felt so
self-conscious about my own ignorance of some really basic stuff that I hesitated to ask my peers
for pointers.

And there was a gap in the educational materials available online between hand-wavy things that only
explained by way of analogy, and in-the-weeds things that only explained by way of inscrutable
mathematical proofs. I wanted to have a clear grasp of the math at work.

And I've found that that is possible: The basic concepts underlying crypto are actually well within
reach using nothing but high-school math.

The purpose of this article is to explain crypto while still respecting your intelligence. I'll
focus on these five operations:

1. Symmetric encryption
1. Random number generation
1. Pseudo-random number generation
1. Hashes
1. Signatures
1. Asymmetric encryption

## Prologue: Numbers all the way down

<figure class='figure-xs'>

![](/images/posts/crypto/ascii.png)

The [ASCII](https://en.wikipedia.org/wiki/ASCII) standard defined numerical equivalents for 95
printable characters: upper-case **A** is 65, lower-case **z** is 122. The
[Unicode](https://en.wikipedia.org/wiki/Unicode) standard has expanded on that to encode 143,859
characters in 154 scripts, from Cyrillic to Hiragana to Emoji.

</figure>

The most fundamental intuition required to understand digital cryptography is that everything is
numbers. That's what "digital" means. Whether it's an instant message or a scan of your bank
statement, it's a series of numbers.

What that means is that we can think of all of the operations listed above as functions that
take a number and return a different number.

In this article I'll focus on messages consisting of **text**, like `The eagle lands at midnight`.
Over time, we've come up with lots of different ways to express letters and characters as numbers.
The only encodings that matter for our purposes is Unicode (which is a superset of ASCII).

In both ASCII and Unicode, the message `The eagle lands at midnight` is encoded as follows:

```txt
T  h   e      e   a  g   l   e      l   a  n   d   s      a  t      m   i   d   n   i   g   h   t
84 104 101 32 101 97 103 108 101 32 108 97 110 100 115 32 97 116 32 109 105 100 110 105 103 104 116
```

### Toy exercises

1. Write a function that takes an ASCII string and encodes it as an array of bytes.
1. Write a function that takes an array of bytes and decodes it back into a string.
1. Use the [utf8.js](https://github.com/mathiasbynens/utf8.js) package to encode Unicode strings
   into an array of bytes.

## <span>1</span> Symmetric encryption

**Symmetric** (secret-key) encryption is so called because both the sender and the receiver have the
same secret key. (In **asymmetric** encryption, also known as **public-key** encryption, the sender
and receiver have different keys. We'll look at that later.)

Suppose Alice and Bob both know the secret passphrase `Horse Battery Correct Staple`, and Alice is
going to send our message, `The eagle lands at midnight`, to Bob.

Alice converts the message to binary. `84` in binary is `01010100`, `104` is `01101000`, and so on.

```txt
T        h        e        space    e        a        ...
84       104      101      32       101      97
01010100 01101000 01100101 00100000 01100101 01100001
```

She also converts the passphrase to binary.

```txt
H        o        r        s        e        space    ...
72       111      114      115      101      32
01001000 01101111 01110010 01110011 01100101 00100000
```

<aside>

XOR (also notated ⊕) is an operation on two binary digits that returns **1** if the two digits are **different**, and
**0** if they are the **same**:

0 ⊕ 0 = 0  
0 ⊕ 1 = 1  
1 ⊕ 0 = 1  
1 ⊕ 1 = 0

</aside>

To encrypt the message using the passphrase, she takes each bit of the message and the corresponding
bit of the passphrase, and performs an `XOR` operation to come up with a new binary number:

```txt
    01010100 01101000 01100101 00100000 01100101 01100001 ... (message)
XOR 01001000 01101111 01110010 01110011 01100101 00100000 ... (passphrase)
---------------------------------------------------------
    00011100 00000111 00010111 01010011 00000000 01000001 ... (cipher)
```

She gets the following **cipher**, which she can send to Bob:

```txt
00011100 00000111 00010111 01010011 00000000 01000001 ...
```

The `XOR` operation has the useful property that you can run it "backwards" to retrieve one of the
original inputs: if `A ⊕ B = C`, then `C ⊕ B = A`. So when Bob receives the cipher, he can `XOR` it
with the passphrase to recover the original message:

```txt
    00011100 00000111 00010111 01010011 00000000 01000001 ... (cipher)
XOR 01001000 01101111 01110010 01110011 01100101 00100000 ... (passphrase)
---------------------------------------------------------
    01010100 01101000 01100101 00100000 01100101 01100001 ... (message)
```

If the key is as long or longer than the message and you never re-use it, it's equivalent to a spy's
**one-time pad**, which is the gold standard for encryption: It offers **perfect secrecy** because
it is mathematically impossible to crack.

What happens if the message is longer than the key, though?

We _could_ repeat the key as many times as necessary to have a mask that's as long as the text to be
encrypted. Suppose the key is `passw0rd`.

```txt
    The eagle lands at midnight
XOR passw0rdpassw0rdpassw0rdpas
```

This would work, but it would not be very secure. To show why, let's take it to an extreme: Suppose
our key is just the letter **X** (`01011000` in binary).

```txt
    The eagle lands at midnight
XOR XXXXXXXXXXXXXXXXXXXXXXXXXXX
```

```txt
    01010100 01101000 01100101 00100000 01100101 01100001 ... (message)
XOR 01011000 01011000 01011000 01011000 01011000 01011000 ... (repeated key)
    ------------------------------------------------------------
    00001100 00110000 00111101 01111000 00111101 00111001 ... (cipher)
```

If you've ever solved a "cryptogram" in a newspaper or a puzzle book, you might see the problem with
this approach. A cryptogram is an example of a **substitution cipher**: each letter in the alphabet
is substituted with another. For example, this cipher substitutes **A** for **E**, **Q** for **T**,
and so on:

```txt
THE EAGLE LANDS AT MIDNIGHT
QDA AZCIA IZKRP ZQ JFRKFCDQ
```

<figure class='figure-md' >

![](/images/posts/crypto/cryptogram.jpg)

If your grandpa can crack it over coffee, it's probably not secure.

</figure>

Substitution ciphers can be solved so easily that they put them in the newspaper next to crossword
puzzles, so that people can work them out with pencil and paper for fun.

<figure class='figure-xs'>

![](/images/posts/crypto/distribution.png)

In English, **E** is the most common letter, followed by **T**, then **A**, **I**, **N**, **O**, and **S**.
_Source: [Practical Cryptography](http://practicalcryptography.com/ciphers/caesar-cipher/)_

</figure>

How? For one thing, you can use statistics about letter frequency to your advantage: A letter that
appears 12% of the time is likely to be `E`, and so on. The longer the message is (or the more
messages you have to work with) the bigger our statistical sample and the more helpful this
technique is.

Our example of XOR encryption with a repeated single-letter key is just a substitution cipher: Every
**T** (`01010100`) is replaced with `00001100`; every **E** (`01100101`) is replaced with
`00111101`; and so on.

With a longer repeated key like `passw0rd` this wouldn't be quite as easy, but given a long-enough
message, it's still possible. The same logic applies to re-using the same key for multiple messages:
The more examples you have of messages encrypted using the same key, the better your chances of
cracking the code.

In order for our symmetric encryption algorithm to be secure, what we need is a way to "stretch" our
key to the size of the message, **without** repeating it. To do that, first we need to explore the
related concepts of **randomness** and **hashes**.

### Toy exercises

<aside>

A **keyed Caesar cipher** is a substitution cipher that is created using a keyword. Suppose the keyword
is `HIERONYMUS`, then the cipher is as follows:

```txt
ABCDEFGHIJKLMNOPQRSTUVWXYZ
HIERONYMUSABCDFGJKLPQTVWXZ
```

(Note that the keyword must not have any repeated letters.)

In this example, `THE EAGLE LANDS AT MIDNIGHT` becomes `VAM MRSFM FRJYT RV GBYJBSAV`.

</aside>

1. Write a `makeCryptogram` function that takes a message and a keyword, and uses a [keyed Caesar
   cipher](TODO) to create a cryptogram.

2. **(Extra credit!)** Write a `solveCryptogram` that uses the approach described in [this
   article](https://www.ics.uci.edu/~welling/teaching/271fall09/Cryptopaper-hart.pdf) to solve any
   cryptogram.

3. Write an `encrypt` function that takes a message and a key, and using the `XOR` approach described
   above, returns the encrypted message as an array of bytes.

4. Write a `decrypt` function that takes an cipher (generated by the `encrypt` function) and a key,
   and returns the original message.

## Random number generators

A source of unpredictability is a fundamental requirement for any form of information security. If
you can make educated guesses about the next key that a system will generate, then the system's
secrets are no longer secret.

**People** can be a source of randomness. In the examples above, we have Alice and Bob using a secret
passphrase --- `Horse Battery Correct Staple` --- to encrypt and decrypt. That might seem totally
random to you --- unless you've seen this XKCD cartoon.

<figure class='figure-md'>

![Password Strength](https://imgs.xkcd.com/comics/password_strength.png)

Since this passphrase appeared in this cartoon, it's no longer a good choice --- but that hasn't
stopped people from using it!

</figure>

The passwords we humans come up with are often not as random as we think they are. This is partly
because we shrink the total possibility space in various ways that make our passwords easier to
remember; thus `passw0rd` and `abc123`. But even if you take memorability out of the picture
--- say, by asking someone to type a series of random numbers --- the results are more predictable
than we might think.

<figure class='figure-xs'>

![](https://miro.medium.com/max/640/1*pMNDxIQh72rFs7lsW6Ww0w.png)

TODO caption [credit](https://medium.com/@markshovman/human-generated-randomness-ac0e3d2f394f)

</figure>

At any rate, encryption keys are typically not generated by us humans, but by our devices --- our
laptops, our servers, our smartphones. So how well do computers do at generating randomness?

This is a harder problem than it seems. You wouldn't think that unpredictability would be in short
supply. Unpredictability is maybe the most salient feature of physical reality.

> "It is difficult to make predictions, especially about the future." _--- (probably not) Yogi Berra_

In the natural world, entropy is the rule, not the exception. Any victories that we achieve against
it are fleeting in the inexorable march towards the heat death of the universe.

That's why we invented computers; they're a weapon for humanity in this battle against chaos.
They're state machines. Their whole point is to be orderly and predictable. Same input, same output,
every single time.

But what that means is that computers can't really **do** unpredictability. That's the bad news. The
good news is that we are surrounded by entropy, and the trick is to bring that outside randomness
into the computer.

<figure>

![Cloudflare Lava Lamp Wall](https://blog.cloudflare.com/content/images/2017/11/lava-lamps.jpg)

As a source of entropy, Cloudflare's wall of lava lamps is mostly for show. But it does illustrate
the idea that true randomness has to come from the physical world into the computer.

</figure>

Cloudflare famously has a wall of lava lamps in their San Francisco lobby. The movement of the blobs
of wax in the hot oil in a lava lamp is known to be chaotic. A video feed from a camera monitoring
the lava lamps --- plus an additional bit of randomness from the movement of people in the lobby ---
populates an "entropy pool" from which random numbers can be drawn. And it [doesn't stop
there](https://www.cloudflare.com/learning/ssl/lava-lamp-encryption/):

> "The other two main Cloudflare offices are in London and Singapore, and each office has its own
> method for generating random data from real-world inputs. London takes photos of a double-pendulum
> system mounted in the office (a pendulum connected to a pendulum, the movements of which are
> mathematically unpredictable). The Singapore office measures the radioactive decay of a pellet of
> uranium."

The lava lamps and the uranium pellet are more nerdy PR stunts than anything. Any modern device has
several sources of randomness:

- Actual physical sensors like accelerometers and CPU temperature monitors
- Minute variations in input from the user, such as mouse movements and the millisecond-level timing
  of keystrokes
- Details of system's overall state, such as hard drive utilization, IDs of running processes, the
  system clock, or CPU counters

All of these can be combined to create something that's unpredictable enough that we don't need to
keep our webcams pointed at a lava lamp. Modern devices use techniques like these to provide
programmers with truly random numbers.

### Toy exercises

1. Use `window.crypto.getRandomValues` (in the browser) or `crypto.randomBytes` (in NodeJS) to
   generate an array of 32 random bytes.

<figure class='figure-xs'>

![JohnvonNeumann-LosAlamos.gif](https://upload.wikimedia.org/wikipedia/commons/5/5e/JohnvonNeumann-LosAlamos.gif)

"Anyone who considers arithmetical methods of producing random digits is, of course, in a state of
sin.” _--- John von Neumann_

</figure>

## Pseudo-random number generators

A PRNG is a function that takes an initial numeric **seed** and returns a new number. The result can
then be used as the next seed, so that you can generate a long sequence of numbers that is entirely
determined by the initial seed.

That sequence isn't infinitely long: at some point, you're bound to get the seed back as a result,
and then you'll start to repeat the whole sequence. The length of the sequence that you get before
you start repeating yourself is called the PRNG's **period**.

The longer the period, the more useful the PRNG. The Mersenne Twister, a widely-used PRNG invented
in 1997, has a period of 2<sup>19937</sup> − 1. That's a 6000-digit number.

I always kind of figured that pseudo-random number generators (PRNGs) were, as the name suggests,
just a poor substitute for a source of truly random numbers.

It is true that we often use PRNGs when there's not enough "real" entropy to go around. The
system-level sources of entropy change too slowly to be a computer's sole source of random numbers,
so they're typically not used directly; instead they're used to seed PRNGs.

But PRNGs themselves are powerful and essential tools. There are many situations where we need
numbers that are **arbitrary but predictable**. Both types of "randomness" are used extensively in
modern cryptography --- the kind that can be predicted from a seed, and the kind that can't be
predicted at all --- and in many cases a deterministic but "random-looking" sequence is what you
want.

What we mean, exactly, when we say "random-looking" is the subject of many a doctoral thesis; but in
general this is what we want from a PRNG:

- Different seeds should generate different sequences.
- Any given sequence should be statistically indistinguishable from "truly random" numbers.

### Toy exercises

Before the Mersenne Twister was invented, the [linear congruential
generator](https://en.wikipedia.org/wiki/Linear_congruential_generator) (LCG) was a widely-used type of
PRNG. LCGs have the form

_X_<sub>_n_+1</sub> = (_aX_<sub>_n_</sub> + _c_) % _m_

(% is the modulo operator.)

1. Make a linear congruential PRNG using _a_=33, _c_=11, and _m_=100:

   _X_<sub>_n_+1</sub> = (33 _X_<sub>_n_</sub> + 11) % 100

   What is the period of this generator?

2. Repeat this exercise with _a_=8121, _c_=28411, and _m_=134456:

   _X_<sub>_n_+1</sub> = (8121 _X_<sub>_n_</sub> + 28411) % 134456

   What is the period of this generator?

3. (🎁 **Extra credit!**) Implement one of the following PRNGs:

   - Mersenne twister (MT19937)
   - XorShift128+

## Hashes

Conceptually, hashing functions and PRNGs are closely related. They're both **deterministic** --- for a given input, you'll

- scrambles a message in such a way that although you always get the same output, you can't recover
  the original message from that output
- some uses for hashes:
  - verify that someone knows a secret X without knowing the secret yourself
  - map a large number to a small one: for example, to obtain a compact "fingerprint" for a large
    file
  - "stretch" a short string
- a hash function maps a number `a` into another number `x`: `h(a) = x`, such that
  - for any `a` you'll always get the same result `x`
  - even if you know `x` **and** you know how it was calculated, it's infeasible to back out what
    `a` was without just trying every possible value of `a`
  - `h(a+1)` and `h(a)` are wildly different
  - you can be almost sure that you won't find two numbers `a` and `b` such that `h(a) = h(b)`
- **NaCl:** SHA-512

## Digital signatures

- **NaCl:** ed25519

## Asymmetric (public-key) encryption

- scrambles a message for a recipient without knowing their secret key; instead we know a public
  key, which is derived from their secret key but can't be
- from https://math.berkeley.edu/~kpmann/encryption.pdf
  - great walk-through of the mechanics of encryption, which I've replicated here
    http://repl.it/@HerbCaudill/PublicKeyEncryptionPOC
  - ^^Public-key crypto is between 1,000 and 10,000 times slower than conventional cryptography.^^
    As a result, public-key cryptography is more often used as a solution to the key-management
    problem, rather than as direct cryptography. People employ public-key to distribute regular,
    private keys, which are then used to encrypt and decrypt actual messages.
- **NaCl:** x25519, xsalsa20, poly1305

- the mathematics behind all of this - pseudo-random numbers, hashes, symmetric and asymmetric
  encryption, and signatures - all stems from mathematical operations that are easy to do but hard
  to reverse.

  - Public-key encryption, for example, is based on the fact that it's easy to multiply two big
    numbers, but vastly harder to figure out what the two numbers were. So much harder that it's
    impossible as a practical matter, if the numbers are big enough.
    - Take two random large prime numbers like `31060011417247013446386700292411` and
      `15828351641710476406499702166851`. Any computer made in the last couple of decades could
      multiply the two numbers together to get
      `491628782707727906284029372629196460298670083807451692011067761`in less than a millisecond.
      Heck, a bright sixth-grader could do it with enough time and motivation. But if you just have
      the result, figuring out what two numbers were multiplied together by brute force would
      require testing something like 10^32 possibilities; if you could test one billion candidates a
      second, it would take 10^23 seconds - about 100,000 times the lifetime of the universe. And
      you can't do much better than brute force.

- How SSL works

  - There's an asymmetry in that
    - the server doesn't care about the client's identity, but the client does, and needs to confirm
      the server's credentials via a trusted third party
    - the server covers the costs of that trusted third party (a certification authority)
  - Handshake http://cloudflare.com/learning/ssl/what-happens-in-a-tls-handshake/
    - **Client** sends hello + random `Rc`
    - **Server** sends hello + cert(`S`, `s`) + random `Rs`
    - **Client** verifies cert, sends random premaster secret `Rp`, encrypted with `S` (Server
      public key) from cert
    - **Server** decrypts premaster secret using `s` (Server secret key)
    - Both **Client** and **Server** derive a symmetric key `k` using `hash(Rc + Rs + Rp)`
    - All subsequent communication is symmetrically encrypted using `k`
